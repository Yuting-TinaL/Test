{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuting-TinaL/Test/blob/main/GenAI_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 2: Prompt Engineering with Text Summarization\n",
        "\n",
        "Welcome to the hands-on lab for Week 2. In this notebook, we will explore different types of prompt engineering techniques using the `Flan-T5 base` model, with a focus on **text summarization**. The aim is to help you understand how crafting effective prompts can lead to significantly better outputs from large language models (LLMs).\n",
        "\n",
        "## Sections Covered:\n",
        "1. Zero-shot prompting\n",
        "2. One-shot prompting\n",
        "3. Few-shot prompting\n",
        "4. Chain-of-thought prompting\n",
        "5. Prompt refinement and comparison\n",
        "\n",
        "Let's get started!\n"
      ],
      "metadata": {
        "id": "tD90NvCRhwR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setting up the Environment\n",
        "\n",
        "First, we need to import the required libraries and ensure that we have the `Flan-T5 base` model loaded.\n"
      ],
      "metadata": {
        "id": "PvwBv2qchyyf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDb20EMrhuLw"
      },
      "outputs": [],
      "source": [
        "# Install the necessary libraries\n",
        "!pip install transformers\n",
        "\n",
        "# Import the required modules\n",
        "from transformers import pipeline\n",
        "\n",
        "# Check if a GPU is available\n",
        "import torch\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# Load the Flan-T5 base model for text summarization\n",
        "model = pipeline(\"summarization\", model=\"google/flan-t5-base\", device=device)\n",
        "\n",
        "print(\"Environment set up. Model loaded on:\", \"GPU\" if device == 0 else \"CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Zero-shot Prompting\n",
        "\n",
        "Zero-shot prompting refers to asking the model to perform a task (summarization in this case) without providing any examples. The model uses its training to infer what the prompt is asking.\n",
        "\n",
        "### Example 1: Text Summarization\n",
        "Let's ask the model to summarize a paragraph without giving it any examples.\n"
      ],
      "metadata": {
        "id": "tOCdJpnjh13r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of zero-shot prompt for summarization\n",
        "text = \"\"\"\n",
        "Generative AI is transforming the field of artificial intelligence by enabling machines to create content autonomously.\n",
        "This technology can generate text, images, music, and even code, impacting industries worldwide.\n",
        "\"\"\"\n",
        "\n",
        "# Zero-shot prompt for summarization\n",
        "prompt = \"Summarize the following text: \" + text\n",
        "response = model(prompt)\n",
        "\n",
        "print(\"Zero-shot Summary:\", response[0]['summary_text'])"
      ],
      "metadata": {
        "id": "XkbsKifCh5KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. One-shot Prompting\n",
        "\n",
        "One-shot prompting involves providing the model with a single example of how to perform a task. This helps guide the model toward the desired output.\n",
        "\n",
        "### Example: Text Summarization\n",
        "Let's use one-shot prompting to guide the model to summarize a paragraph."
      ],
      "metadata": {
        "id": "Yr8AT1ZwiR5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of one-shot prompt for summarization\n",
        "text = \"\"\"\n",
        "AI is rapidly changing various sectors, including healthcare, finance, and education.\n",
        "It allows for more efficient data analysis, predictive modeling, and automation of complex tasks,\n",
        "making it an essential tool for the future.\n",
        "\"\"\"\n",
        "\n",
        "# One-shot prompt with a single example\n",
        "prompt = \"\"\"Summarize the following text:\n",
        "Example: \"The weather today is very unpredictable and varies from place to place.\"\n",
        "Summary: \"The weather is unpredictable.\"\n",
        "\n",
        "Text: \"\"\" + text\n",
        "response = model(prompt)\n",
        "\n",
        "print(\"One-shot Summary:\", response[0]['summary_text'])"
      ],
      "metadata": {
        "id": "u8kA32OGiS8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Few-shot Prompting\n",
        "\n",
        "Few-shot prompting provides the model with a few examples to better illustrate the task. This often improves the model's performance compared to zero-shot and one-shot prompting.\n",
        "\n",
        "### Example: Text Summarization\n",
        "Let's provide the model with multiple examples to summarize the input text."
      ],
      "metadata": {
        "id": "-8HnMi3eibLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of few-shot prompt for summarization\n",
        "text = \"\"\"\n",
        "The development of renewable energy is crucial for reducing our reliance on fossil fuels.\n",
        "It is expected that renewable energy sources like solar, wind, and hydropower will play a significant role in the global energy mix in the coming decades.\n",
        "\"\"\"\n",
        "\n",
        "# Few-shot prompt with two examples\n",
        "prompt = \"\"\"\n",
        "Summarize the following text:\n",
        "Example 1: \"Technology is advancing rapidly in the field of AI and machine learning.\"\n",
        "Summary: \"AI technology is advancing rapidly.\"\n",
        "\n",
        "Example 2: \"The economic policies of the country are aimed at reducing inflation and boosting growth.\"\n",
        "Summary: \"Economic policies aim to reduce inflation and boost growth.\"\n",
        "\n",
        "Text: \"\"\" + text\n",
        "response = model(prompt)\n",
        "\n",
        "print(\"Few-shot Summary:\", response[0]['summary_text'])"
      ],
      "metadata": {
        "id": "tLdAjiJAicSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Chain-of-thought Prompting\n",
        "\n",
        "Chain-of-thought prompting guides the model step-by-step, showing how to break down complex tasks into smaller, simpler ones before summarizing.\n",
        "\n",
        "### Example: Text Summarization with Chain-of-thought\n",
        "Letâ€™s break down a longer paragraph into smaller components before asking for a summary."
      ],
      "metadata": {
        "id": "PvzPPQINiesM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of chain-of-thought prompting for summarization\n",
        "text = \"\"\"\n",
        "Artificial intelligence (AI) has seen a rapid development in recent years. It has been applied to various industries, including healthcare,\n",
        "where it is used for diagnostic tools and predictive analytics. AI has also been integrated into autonomous vehicles and robotics,\n",
        "showing promise for a wide range of applications in both consumer and industrial markets.\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "Break down the following text step by step, then summarize it.\n",
        "Step 1: Identify the main topic: The rapid development of AI.\n",
        "Step 2: Highlight the key applications: healthcare, autonomous vehicles, and robotics.\n",
        "Step 3: Note the industries impacted: consumer and industrial markets.\n",
        "\n",
        "Summary: \"\"\" + text\n",
        "response = model(prompt)\n",
        "\n",
        "print(\"Chain-of-thought Summary:\", response[0]['summary_text'])"
      ],
      "metadata": {
        "id": "8tLsxrzwigML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Prompt Refinement and Comparison\n",
        "\n",
        "Now that we've seen how different prompt engineering techniques work, let's compare the outputs generated from various methods. The goal here is to refine our prompts to get better, more accurate results.\n",
        "\n",
        "### Task: Refine the Summarization Prompt\n",
        "We'll use both zero-shot and few-shot prompting to see how the summarization changes.\n",
        "\n",
        "#### Zero-shot:"
      ],
      "metadata": {
        "id": "Hfmb6Ccjihbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-shot prompt for summarization\n",
        "text = \"\"\"\n",
        "AI is shaping the future of technology by enabling more efficient processes and automation.\n",
        "It plays a key role in sectors like healthcare, education, and finance, providing innovative solutions to complex challenges.\n",
        "\"\"\"\n",
        "prompt = \"Summarize the following text: \" + text\n",
        "response_zero_shot = model(prompt)\n",
        "\n",
        "print(\"Zero-shot Summary:\", response_zero_shot[0]['summary_text'])"
      ],
      "metadata": {
        "id": "gBLvCkwNijRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Few-shot:\n"
      ],
      "metadata": {
        "id": "UtWfSQiFilMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-shot prompt for summarization\n",
        "prompt = \"\"\"\n",
        "Summarize the following text:\n",
        "Example 1: \"Technology is rapidly advancing and transforming various industries.\"\n",
        "Summary: \"Technology is advancing rapidly.\"\n",
        "\n",
        "Example 2: \"Economic reforms are being implemented to boost growth and reduce inflation.\"\n",
        "Summary: \"Economic reforms aim to boost growth and reduce inflation.\"\n",
        "\n",
        "Text: AI is shaping the future of technology by enabling more efficient processes and automation.\n",
        "It plays a key role in sectors like healthcare, education, and finance, providing innovative solutions to complex challenges.\n",
        "\"\"\"\n",
        "response_few_shot = model(prompt)\n",
        "\n",
        "print(\"Few-shot Summary:\", response_few_shot[0]['summary_text'])"
      ],
      "metadata": {
        "id": "j7jaulzgil22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Conclusion\n",
        "\n",
        "In this lab, we explored several types of prompt engineering techniques using text summarization:\n",
        "- Zero-shot prompting\n",
        "- One-shot prompting\n",
        "- Few-shot prompting\n",
        "- Chain-of-thought prompting\n",
        "\n",
        "We observed how different prompt formats affect the quality of the output generated by the `Flan-T5 base` model. In the next session, weâ€™ll dive deeper into **fine-tuning** models to further enhance their performance for specific tasks."
      ],
      "metadata": {
        "id": "xEJARaPqiod1"
      }
    }
  ]
}